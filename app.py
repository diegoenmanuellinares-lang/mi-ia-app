import streamlit as st
import google.generativeai as genai

# CONFIGURACI√ìN DE SEGURIDAD (Carga la API Key desde los Secrets de Streamlit)
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("Falta la configuraci√≥n de la API Key en los Secretos de Streamlit.")

# INSTRUCCIONES ACAD√âMICAS (Personalidad de la IA para idiomas)
# Estas instrucciones definen el comportamiento de tu tutor personalizado
instruction = (
    "Eres 'L'Atelier Fran√ßais AI', un tutor de franc√©s especializado para estudiantes universitarios. "
    "REGLA 1: Siempre incluye la transcripci√≥n fon√©tica IPA entre corchetes [ ] para cada palabra o frase en franc√©s. "
    "REGLA 2: Usa un tono acad√©mico, amable y profesional. "
    "REGLA 3: Proporciona ejemplos claros y, si es necesario, cita fuentes seg√∫n la norma APA 7ma edici√≥n."
)

# INTERFAZ DE LA APLICACI√ìN (Streamlit UI)
st.set_page_config(page_title="L'Atelier Fran√ßais AI", page_icon="üá´üá∑", layout="centered")

st.title("üá´üá∑ L'Atelier Fran√ßais AI")
st.markdown("### Tu asistente acad√©mico de franc√©s con fon√©tica IPA")
st.info("Este proyecto ha sido desarrollado para apoyar el aprendizaje de idiomas con rigor cient√≠fico.")

# Inicializar el historial de conversaci√≥n en la sesi√≥n
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar los mensajes previos del chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Entrada de texto del usuario
if prompt := st.chat_input("Escribe tu pregunta sobre franc√©s aqu√≠..."):
    # Agregar mensaje del usuario al historial
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Configuraci√≥n del modelo Gemini (Correcci√≥n del error NotFound)
    # Se usa el prefijo 'models/' para asegurar la ruta correcta en la API
    model = genai.GenerativeModel(
        model_name="models/gemini-1.5-flash",
        system_instruction=instruction
    )
    
    # Generar respuesta
    with st.chat_message("assistant"):
        try:
            response = model.generate_content(prompt)
            st.markdown(response.text)
            # Agregar respuesta de la IA al historial
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"Hubo un error al conectar con la IA: {e}")
